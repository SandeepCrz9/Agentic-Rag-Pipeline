{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install langchain-community\n",
        "!pip install llama-index\n",
        "!pip install llama-index-llms-langchain\n",
        "%pip install -U langchain-google-genai\n",
        "%pip install llama-index-embeddings-gemini"
      ],
      "metadata": {
        "id": "vJGCw9nUGZr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oROpRKKuGSoD",
        "outputId": "654c2c7e-3417-4ef9-87b2-701a956d9f46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Google AI API key: ··········\n"
          ]
        }
      ],
      "source": [
        "# Set Gemini API Key\n",
        "\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "Gemini_api_key = getpass(\"Enter your Google AI API key: \") # Your Gemini Api key which is used as our LLM in the backend"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "google_search_api_key = getpass(\"Enter your Google Search API key: \")\n",
        "google_search_cx = getpass(\"Enter your Google Search Engine ID (CX): \")\n",
        "\n",
        "# Set environment variables for Google Search\n",
        "os.environ[\"GOOGLE_API_KEY\"] = google_search_api_key # Input your google search api which is used for our search engine\n",
        "os.environ[\"GOOGLE_CSE_ID\"] = google_search_cx # Input your search engine id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nno-51LuDZO2",
        "outputId": "654e7d7b-696a-47db-ffe9-e0bbe06b5362"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Google Search API key: ··········\n",
            "Enter your Google Search Engine ID (CX): ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nQpm0tcGSoD"
      },
      "outputs": [],
      "source": [
        "# Required Imports\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "from langchain.agents import Tool, AgentExecutor, create_tool_calling_agent\n",
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "from llama_index.embeddings.gemini import GeminiEmbedding\n",
        "from llama_index.core import ( SimpleDirectoryReader,VectorStoreIndex,StorageContext, load_index_from_storage, Settings)\n",
        "from llama_index.core.tools import QueryEngineTool, ToolMetadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjcSkf7PGSoD",
        "outputId": "d53082e0-da44-4bf3-f535-38a59802eaef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-56-676295584.py:5: DeprecationWarning: Call to deprecated class GeminiEmbedding. (Should use `llama-index-embeddings-google-genai` instead, using Google's latest unified SDK. See: https://docs.llamaindex.ai/en/stable/examples/embeddings/google_genai/)\n",
            "  embed_model = GeminiEmbedding(\n"
          ]
        }
      ],
      "source": [
        "# LLM\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\",google_api_key=Gemini_api_key, temperature=0, disable_streaming=False)\n",
        "\n",
        "# Embedding Model\n",
        "embed_model = GeminiEmbedding(\n",
        "    model=\"models/embedding-001\", api_key=Gemini_api_key, embed_batch_size=100\n",
        ")\n",
        "\n",
        "# Set Llamaindex Configs\n",
        "Settings.llm = llm\n",
        "Settings.embed_model = embed_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zO7VyLbGSoE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sybWTASGSoE"
      },
      "source": [
        "#### Use LlamaIndex to create Query Engines for individual docs\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDGL3Qb5kFbv",
        "outputId": "9b7c3c14-dc46-43b8-9028-1fc010f80612"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "Tm0WhQ7UGSoE",
        "outputId": "bcc1e45a-ec60-4b20-b04c-2262c3b2fb7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading llama_index.core.storage.kvstore.simple_kvstore from /content/drive/MyDrive/my_llama_indexes/lyft_form10k_2021/docstore.json.\n",
            "Index is not present. We need it to create it again.\n",
            "Creating Index..\n",
            "LlamaIndex Query Engines created successfully.\n"
          ]
        }
      ],
      "source": [
        "#Building Indexes for each of the Documents\n",
        "try:\n",
        "    storage_context = StorageContext.from_defaults(\n",
        "        persist_dir=\"/content/drive/MyDrive/my_llama_indexes/lyft_form10k_2021\"\n",
        "    )\n",
        "    lyft_index = load_index_from_storage(storage_context)\n",
        "\n",
        "    storage_context = StorageContext.from_defaults(\n",
        "        persist_dir=\"/content/drive/MyDrive/my_llama_indexes/uber_form10k_2021\"\n",
        "    )\n",
        "    uber_index = load_index_from_storage(storage_context)\n",
        "\n",
        "    index_loaded = True\n",
        "    print(\"Index was already created. We just loaded it from the local storage.\")\n",
        "\n",
        "except:\n",
        "\n",
        "    index_loaded = False\n",
        "    print(\"Index is not present. We need it to create it again.\")\n",
        "\n",
        "if not index_loaded:\n",
        "\n",
        "    print(\"Creating Index..\")\n",
        "\n",
        "    # load data\n",
        "    lyft_docs = SimpleDirectoryReader(\n",
        "        input_files=[\"/content/lyft_Form10k_2021.pdf\"]\n",
        "    ).load_data()\n",
        "    uber_docs = SimpleDirectoryReader(\n",
        "        input_files=[\"/content/Uber_Form10K_2021.pdf\"]\n",
        "    ).load_data()\n",
        "\n",
        "    # build index\n",
        "    lyft_index = VectorStoreIndex.from_documents(lyft_docs)\n",
        "    uber_index = VectorStoreIndex.from_documents(uber_docs)\n",
        "\n",
        "    # persist index\n",
        "    lyft_index.storage_context.persist(persist_dir=\"/content/drive/MyDrive/my_llama_indexes/lyft_form10k_2021\")\n",
        "    uber_index.storage_context.persist(persist_dir=\"/content/drive/MyDrive/my_llama_indexes/uber_form10k_2021\")\n",
        "\n",
        "    index_loaded = True\n",
        "\n",
        "\n",
        "\n",
        "#Creating Query engines on top of the indexes\n",
        "\n",
        "lyft_engine = lyft_index.as_query_engine(similarity_top_k=3)\n",
        "uber_engine = uber_index.as_query_engine(similarity_top_k=3)\n",
        "\n",
        "print(\"LlamaIndex Query Engines created successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asTNQe12GSoF"
      },
      "outputs": [],
      "source": [
        "lyft_index.storage_context.persist(persist_dir=\"/content/drive/MyDrive/my_llama_indexes/lyft_form10k_2021\")\n",
        "uber_index.storage_context.persist(persist_dir=\"/content/drive/MyDrive/my_llama_indexes/uber_form10k_2021\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SL3619heGSoF"
      },
      "source": [
        "#### We will now use the LlamaIndex QueryEngineTool abstraction to convert our query engines into Tools which can be used with Agents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__CPjaSdGSoF"
      },
      "outputs": [],
      "source": [
        "#creating tools for each of our query engines\n",
        "\n",
        "query_engine_tools = [\n",
        "\n",
        "    QueryEngineTool(\n",
        "        query_engine=lyft_engine,\n",
        "        metadata=ToolMetadata(\n",
        "            name=\"lyft_10k\",\n",
        "            description=(\n",
        "                \"Provides information about Lyft financials for year 2021. \"\n",
        "                \"Use a detailed plain text question as input to the tool.\"\n",
        "            ),\n",
        "        ),\n",
        "    ),\n",
        "    QueryEngineTool(\n",
        "        query_engine=uber_engine,\n",
        "        metadata=ToolMetadata(\n",
        "            name=\"uber_10k\",\n",
        "            description=(\n",
        "                \"Provides information about Uber financials for year 2021. \"\n",
        "                \"Use a detailed plain text question as input to the tool.\"\n",
        "            ),\n",
        "        ),\n",
        "    ),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQrVVOwSGSoF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZPh6SOcGSoF"
      },
      "source": [
        "### Converting LlamaIndex Tools to Langchain Compatible Format Tools\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kckT6QBGSoF",
        "outputId": "68fbfead-fe09-4949-e748-470f6c260545"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<llama_index.core.tools.query_engine.QueryEngineTool at 0x7aa9675afa50>,\n",
              " <llama_index.core.tools.query_engine.QueryEngineTool at 0x7aa964297990>]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "#before conversion\n",
        "query_engine_tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aY8I3oMCGSoF",
        "outputId": "f66a8def-0005-4f3a-f99b-736f1a0dcc50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No of LlamaIndex Tools: 2\n"
          ]
        }
      ],
      "source": [
        "llamaindex_to_langchain_converted_tools = [t.to_langchain_tool() for t in query_engine_tools]\n",
        "\n",
        "print(\"No of LlamaIndex Tools:\", len(llamaindex_to_langchain_converted_tools))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKUSMDxuGSoG",
        "outputId": "a481bdac-f93a-4281-834c-a5b3e1f2a98d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Tool(name='lyft_10k', description='Provides information about Lyft financials for year 2021. Use a detailed plain text question as input to the tool.', args_schema=<class 'llama_index.core.tools.types.DefaultToolFnSchema'>, func=<BoundFunctionWrapper at 0x7aa95476a570 for method at 0x7aa963cd1700>),\n",
              " Tool(name='uber_10k', description='Provides information about Uber financials for year 2021. Use a detailed plain text question as input to the tool.', args_schema=<class 'llama_index.core.tools.types.DefaultToolFnSchema'>, func=<BoundFunctionWrapper at 0x7aa954768e40 for method at 0x7aa964416b00>)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "#after conversion\n",
        "llamaindex_to_langchain_converted_tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8bLWkSuGSoG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I30tHBRMGSoG"
      },
      "source": [
        "#### Define an Additional Langchain Tool for External Web Search Functionality"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install google-search-results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWmnoQ2GGhkx",
        "outputId": "82e733fa-47f5-4f90-caea-7a12b9622d29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-search-results\n",
            "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from google-search-results) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (2025.6.15)\n",
            "Building wheels for collected packages: google-search-results\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32093 sha256=741dc8827238842311eb70351db24ccce866561e89a3178b42cd5daa4a9b4123\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/42/3e/aeb691b02cb7175ec70e2da04b5658d4739d2b41e5f73cd06f\n",
            "Successfully built google-search-results\n",
            "Installing collected packages: google-search-results\n",
            "Successfully installed google-search-results-2.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgYYVgGIGSoG"
      },
      "outputs": [],
      "source": [
        "from langchain_community.utilities import GoogleSearchAPIWrapper\n",
        "\n",
        "search = GoogleSearchAPIWrapper()\n",
        "\n",
        "google_search_tool = Tool(\n",
        "    func=search.run,\n",
        "    name=\"google_search\",\n",
        "    description=\"Use for when you need to perform an internet search to find information that another tool can not provide.\"\n",
        ")\n",
        "\n",
        "langchain_tools = [google_search_tool]\n",
        "\n",
        "'''search = DuckDuckGoSearchRun()\n",
        "\n",
        "duckduckgo_tool = Tool(\n",
        "        name='DuckDuckGoSearch',\n",
        "        func= search.run,\n",
        "        description='Use for when you need to perform an internet search to find information that another tool can not provide.'\n",
        ")\n",
        "\n",
        "langchain_tools = [duckduckgo_tool]'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63FaEeQ5GSoG",
        "outputId": "c2eb97a3-46d8-4160-92f4-0647fb4746b2"
      },
      "outputs": [],
      "source": [
        "langchain_tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IseejIEKGSoG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgEzeTj_GSoG"
      },
      "source": [
        "#### Combine Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJnxekUqGSoG",
        "outputId": "f7427055-56b0-43b5-e42a-9b605fa2eed9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No of Final tools: 3\n"
          ]
        }
      ],
      "source": [
        "#Combine to create final list of tools\n",
        "tools = llamaindex_to_langchain_converted_tools + langchain_tools\n",
        "\n",
        "print(\"No of Final tools:\", len(tools))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyyNP9i6GSoG",
        "outputId": "1bbf0484-5e23-4fdf-830b-33fe5eda602b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Tool(name='lyft_10k', description='Provides information about Lyft financials for year 2021. Use a detailed plain text question as input to the tool.', args_schema=<class 'llama_index.core.tools.types.DefaultToolFnSchema'>, func=<BoundFunctionWrapper at 0x7aa95476a570 for method at 0x7aa963cd1700>),\n",
              " Tool(name='uber_10k', description='Provides information about Uber financials for year 2021. Use a detailed plain text question as input to the tool.', args_schema=<class 'llama_index.core.tools.types.DefaultToolFnSchema'>, func=<BoundFunctionWrapper at 0x7aa954768e40 for method at 0x7aa964416b00>),\n",
              " Tool(name='google_search', description='Use for when you need to perform an internet search to find information that another tool can not provide.', func=<bound method GoogleSearchAPIWrapper.run of GoogleSearchAPIWrapper(search_engine=<googleapiclient.discovery.Resource object at 0x7aa954a15190>, google_api_key='AIzaSyCBJJa3tSsKaYBqF01iIh57_0QJ7nFoHUE', google_cse_id='504f230b0a9874aef', k=10, siterestrict=False)>)]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkvV4cH0GSoH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCNbYUe9GSoH"
      },
      "source": [
        "#### Inititalize Langchain's Tool Calling Agent with an Agent Executor\n",
        "\n",
        "\n",
        "By creating the 'tool calling agent', we provide access to multiple tools for the LLM. The agent intelligently chooses to repeatedly call the appropriate tools and receives results until the user's query is resolved.\n",
        "\n",
        "The tool-calling agent is the newest, and more general agent implementation that supports a wide variety of LLM providers such as OpenAI, Anthropic, Google Gemini, Mistral, and others.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyAfNgkMGSoH",
        "outputId": "27bf775d-e7e0-4baf-cfdb-b245ecb9dac4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RunnableAssign(mapper={\n",
              "  agent_scratchpad: RunnableLambda(lambda x: message_formatter(x['intermediate_steps']))\n",
              "})\n",
              "| ChatPromptTemplate(input_variables=['input'], optional_variables=['agent_scratchpad', 'chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x7aa97f5f36a0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x7aa97f5f36a0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': [], 'agent_scratchpad': []}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a stock market expert.You will answer questions about Uber and Lyft companies as in the persona of a veteran stock market investor.'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad', optional=True)])\n",
              "| RunnableBinding(bound=ChatGoogleGenerativeAI(model='models/gemini-2.0-flash', google_api_key=SecretStr('**********'), temperature=0.0, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x7aa9642c5110>, default_metadata=(), model_kwargs={}), kwargs={'tools': [{'type': 'function', 'function': {'name': 'lyft_10k', 'description': 'Provides information about Lyft financials for year 2021. Use a detailed plain text question as input to the tool.', 'parameters': {'properties': {'input': {'type': 'string'}}, 'required': ['input'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'uber_10k', 'description': 'Provides information about Uber financials for year 2021. Use a detailed plain text question as input to the tool.', 'parameters': {'properties': {'input': {'type': 'string'}}, 'required': ['input'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'google_search', 'description': 'Use for when you need to perform an internet search to find information that another tool can not provide.', 'parameters': {'properties': {'__arg1': {'title': '__arg1', 'type': 'string'}}, 'required': ['__arg1'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
              "| ToolsAgentOutputParser()"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "system_context = \"You are a stock market expert.\\\n",
        "You will answer questions about Uber and Lyft companies as in the persona of a veteran stock market investor.\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            system_context,\n",
        "        ),\n",
        "        (\"placeholder\", \"{chat_history}\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Construct the Tools agent\n",
        "agent = create_tool_calling_agent(llm, tools, prompt,)\n",
        "agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsjYvaD5GSoH",
        "outputId": "62e2d0ca-5a76-4e0b-f79f-68860422204f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
              "  agent_scratchpad: RunnableLambda(lambda x: message_formatter(x['intermediate_steps']))\n",
              "})\n",
              "| ChatPromptTemplate(input_variables=['input'], optional_variables=['agent_scratchpad', 'chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x7aa97f5f36a0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x7aa97f5f36a0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': [], 'agent_scratchpad': []}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a stock market expert.You will answer questions about Uber and Lyft companies as in the persona of a veteran stock market investor.'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad', optional=True)])\n",
              "| RunnableBinding(bound=ChatGoogleGenerativeAI(model='models/gemini-2.0-flash', google_api_key=SecretStr('**********'), temperature=0.0, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x7aa9642c5110>, default_metadata=(), model_kwargs={}), kwargs={'tools': [{'type': 'function', 'function': {'name': 'lyft_10k', 'description': 'Provides information about Lyft financials for year 2021. Use a detailed plain text question as input to the tool.', 'parameters': {'properties': {'input': {'type': 'string'}}, 'required': ['input'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'uber_10k', 'description': 'Provides information about Uber financials for year 2021. Use a detailed plain text question as input to the tool.', 'parameters': {'properties': {'input': {'type': 'string'}}, 'required': ['input'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'google_search', 'description': 'Use for when you need to perform an internet search to find information that another tool can not provide.', 'parameters': {'properties': {'__arg1': {'title': '__arg1', 'type': 'string'}}, 'required': ['__arg1'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
              "| ToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[Tool(name='lyft_10k', description='Provides information about Lyft financials for year 2021. Use a detailed plain text question as input to the tool.', args_schema=<class 'llama_index.core.tools.types.DefaultToolFnSchema'>, func=<BoundFunctionWrapper at 0x7aa95476a570 for method at 0x7aa963cd1700>), Tool(name='uber_10k', description='Provides information about Uber financials for year 2021. Use a detailed plain text question as input to the tool.', args_schema=<class 'llama_index.core.tools.types.DefaultToolFnSchema'>, func=<BoundFunctionWrapper at 0x7aa954768e40 for method at 0x7aa964416b00>), Tool(name='google_search', description='Use for when you need to perform an internet search to find information that another tool can not provide.', func=<bound method GoogleSearchAPIWrapper.run of GoogleSearchAPIWrapper(search_engine=<googleapiclient.discovery.Resource object at 0x7aa954a15190>, google_api_key='AIzaSyCBJJa3tSsKaYBqF01iIh57_0QJ7nFoHUE', google_cse_id='504f230b0a9874aef', k=10, siterestrict=False)>)], return_intermediate_steps=True, max_iterations=10, handle_parsing_errors=True)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "# Create an agent executor by passing in the agent and tools\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, return_intermediate_steps=True, handle_parsing_errors=True, max_iterations=10)\n",
        "agent_executor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suXX_tUNGSoH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgfaCYbNGSoH"
      },
      "source": [
        "### Testing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "NqxV0s80GSoH",
        "outputId": "26130367-932b-4f90-9291-aeeaf84705c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `lyft_10k` with `{'input': 'What employee benefits are offered by Lyft?'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3mLyft offers drivers 24/7 support, earnings tools, education resources, and other support to help them meet their personal goals. They also have Driver Hubs and certain field locations in major cities that serve as gathering places and offer in-person support.\u001b[0m\u001b[32;1m\u001b[1;3mLyft provides its drivers with a range of benefits, including 24/7 support, various earnings tools, educational resources, and comprehensive support aimed at helping them achieve their individual objectives. Additionally, Lyft operates Driver Hubs and select field locations in key urban centers, creating communal spaces where drivers can connect and access in-person assistance.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "Final Response: Lyft provides its drivers with a range of benefits, including 24/7 support, various earnings tools, educational resources, and comprehensive support aimed at helping them achieve their individual objectives. Additionally, Lyft operates Driver Hubs and select field locations in key urban centers, creating communal spaces where drivers can connect and access in-person assistance.\n"
          ]
        }
      ],
      "source": [
        "question =  \"What are employee benfits offered by lyft?\"\n",
        "\n",
        "response = agent_executor.invoke({\"input\": question})\n",
        "\n",
        "print(\"\\nFinal Response:\", response['output'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwjZG6R2GSoH"
      },
      "outputs": [],
      "source": [
        "#It invoked the lyft query engine tool as desired."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzY3psazGSoI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "R_sE0K1-GSoI",
        "outputId": "24a97dbb-3efb-427f-d685-5986f5a880a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `uber_10k` with `{'input': 'Was Uber profitable in 2021?'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3mUber was not profitable in 2021, with a net loss attributable to Uber Technologies, Inc. of $496 million.\u001b[0m\u001b[32;1m\u001b[1;3mAs a seasoned investor, I can tell you that Uber was not profitable in 2021. They had a net loss of $496 million. It's crucial to look beyond just a single year, though. I'd recommend digging into their financials, analyzing their revenue growth, and understanding their cost structure before making any investment decisions.\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "Final Response: As a seasoned investor, I can tell you that Uber was not profitable in 2021. They had a net loss of $496 million. It's crucial to look beyond just a single year, though. I'd recommend digging into their financials, analyzing their revenue growth, and understanding their cost structure before making any investment decisions.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "question =  \"Is Uber Profitable\"\n",
        "\n",
        "response = agent_executor.invoke({\"input\": question})\n",
        "\n",
        "print(\"\\nFinal Response:\", response['output'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qLYD6VVGSoI"
      },
      "outputs": [],
      "source": [
        "#It invoked the uber query engine tool as desired."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpLVnHDxGSoI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsYNXfG1GSoI",
        "outputId": "277263df-ac9c-46f9-df12-5b5d47aedf40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `google_search` with `who is the CEO of Microsoft`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[38;5;200m\u001b[1;3mSatya Narayana Nadella is an Indian-born American business executive who is the chairman and chief executive officer (CEO) of Microsoft, succeeding Steve ... Satya Nadella is Chairman and Chief Executive Officer of Microsoft. Before being named CEO in February 2014, Nadella held leadership roles in both enterprise ... Satya Nadella Satya Nadella is an influencer · Chairman and CEO at Microsoft · View mutual connections with Satya · Welcome back · About · Articles by Satya. Dec 6, 2021 ... Gates did the most for personal computing. Nadella did the most for the open source community. Reply reply. Award Share. ar243. • 4y ago. Gates ... Satya Narayana Nadella is the chief executive officer (CEO) of Microsoft. Under him, Microsoft has more cloud computing revenue than Google, more subscribers ... Dec 14, 2023 ... LIST OF MICROSOFT CEOS THROUGH TIME · Bill Gates (1975-2000) · Steve Ballmer (2000-2014) · Satya Nadella (2014-present). ‍. BILL GATES ... Apr 30, 2020 ... This week, CEO Satya Nadella delivered Microsoft's quarterly earnings report to Wall Street—our first in the era of COVID-19. Mar 19, 2024 ... Satya Nadella, Chairman and CEO, shared the below communication today with Microsoft employees. I want to share an exciting and important ... Feb 4, 2014 ... Satya Nadella, an alumnus of the University of Wisconsin-Milwaukee (UWM), is remembered as an extremely talented graduate student who was one of ... Nov 21, 2023 ... We are encouraged by the changes to the OpenAI board. We believe this is a first essential step on a path to more stable, well-informed, and effective ...\u001b[0m\u001b[32;1m\u001b[1;3mThe CEO of Microsoft is Satya Nadella.\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "Final Response: The CEO of Microsoft is Satya Nadella.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "question =  \"Who is the CEO of Microsoft\"\n",
        "\n",
        "response = agent_executor.invoke({\"input\": question})\n",
        "\n",
        "print(\"\\nFinal Response:\", response['output'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4lDOwveGSoI"
      },
      "outputs": [],
      "source": [
        "#Since this information is absent in any of the documents, it invoked the external search tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fer8JpLtGSoI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EGgpbQDGSoR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UGNGgj3GSoR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "GenAiApril24",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
